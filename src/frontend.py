"""
Проект: расшифровка сообщений с автоответчика (из аудио файла в текст)
и создание заявок на основе сообщения.
Веб-интерфейс
Программная инженерия, группа 1.7
"""

# импортируем необходимые библиотеки
import streamlit as st
from transcribe import transcribe, load_model
from categorizer import categorize_ticket, categories, priorities


@st.cache_resource
def load_transcribe_model():
    """
    Вызываем функцию загрузки модели
    Кешируем загрузку модели (экономия ресурсов) через @st.cache_resource

    Returns:
        функцию загрузки модели из модуля transcribe
    """
    return load_model()


# функция вывода полученных данных - временный интерфейс
def output_data(ticket):
    """
    Функция вывода на страницу результата обработки аудио-заявки
    Args:
        ticket (dict): словарь из 3 элементов
               ticket_text (str) - текст заявки / обращения
               category (str) - категория задач, к которой относится заявка
               priority (str) - приоритет выполнения заявки
    """
    st.text_area("Текст тикета: ", ticket["ticket_text"])
    st.markdown("Категория задачи: " + categories[ticket["category"]])
    st.markdown("Приоритет задачи:  **:red[" + priorities[ticket["priority"]] + "]**")


if __name__ == '__main__':
    # выводим приветственное сообщение и кратко обозначаем функционал приложения
    st.title('AI генератор задач для техподдержки')
    st.write("""На основании аудиозаписи автоответчика службы поддержки
             производится перевод аудио в текст, а также определение
             категории задачи и ее приоритета""")

    audio_file = st.file_uploader('Загрузите аудиофайл',
                                  type=['flac'],
                                  accept_multiple_files=False, key=None,
                                  on_change=None)

    # предлагаем пользователю выбрать, локально запускаем модель или по API
    option = st.selectbox(
        'Локальный запуск распознавания или используем API?',
        ('Локально', 'API'), key='option')

    # добавляем кнопку в интерфейс
    btn1 = st.button("Поехали!", key="summ", type="primary")

    # проверяем факт нажатия кнопки пользователем
    if btn1:
        # кнопка нажата, аудиофайл загружен
        if audio_file:
            # проверяем выбор пользователем чекбокса (локально, или по API?)
            if option == 'Локально':
                # пользователь выбрал Локально
                st.write('Локальный запуск')
                # загружаем модель
                model = load_transcribe_model()
                # вызываем функцию транскрибации текста
                ticket_text = transcribe(model, audio_file)
                # вызываем функцию категоризации и приоритезации задачи
                ticket_data = categorize_ticket(ticket_text)
            else:
                # пользователь выбрал "API"
                st.write('Используем API')
              
                # !!!!!!!!!!!!!!!!!!! ЗАГЛУШКА НАЧАЛО !!!!!!!!!!!!!!!!!!!!!!!!!!!
                # вызываем API метод, в который передаем аудио запись
                # и получаем обратно текст, категорию и приоритет
                # ticket_data = get_ticket_api(audio_file)                
                ticket_data = {"ticket_text": "Здесь будет какой текст, который вернет API",
                               "category": 0, "priority": 0}
                # !!!!!!!!!!!!!!!!!!! ЗАГЛУШКА КОНЕЦ !!!!!!!!!!!!!!!!!!!!!!!!!!!

            # выводим на страницу полученные результаты 
            output_data(ticket_data)

        else:
            # указываем пользователю на то, что он не загрузил файл
            st.write('Пожалуйста, загрузите аудиофайл')
